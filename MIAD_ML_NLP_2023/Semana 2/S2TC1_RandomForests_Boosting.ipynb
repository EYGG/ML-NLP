{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de modelos Bagging, Random Forest y XGBoost\n",
    "\n",
    "En este taller podrán poner en práctica sus conocimientos sobre la construcción e implementación de modelos de Bagging, Random Forest y XGBoost. El taller está constituido por 8 puntos, en los cuales deberan seguir las intrucciones de cada numeral para su desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos predicción precio de automóviles\n",
    "\n",
    "En este taller se usará el conjunto de datos de Car Listings de Kaggle donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como año, marca, modelo, entre otras. El objetivo es predecir el precio del automóvil. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21995</td>\n",
       "      <td>2014</td>\n",
       "      <td>6480</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13995</td>\n",
       "      <td>2014</td>\n",
       "      <td>39972</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>17941</td>\n",
       "      <td>2016</td>\n",
       "      <td>18989</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>12493</td>\n",
       "      <td>2014</td>\n",
       "      <td>51330</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>7994</td>\n",
       "      <td>2007</td>\n",
       "      <td>116065</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL   \n",
       "7    21995  2014     6480    False       False        False      True  \\\n",
       "11   13995  2014    39972    False       False        False     False   \n",
       "167  17941  2016    18989    False       False        False     False   \n",
       "225  12493  2014    51330    False       False        False      True   \n",
       "270   7994  2007   116065    False        True        False     False   \n",
       "\n",
       "     M_CamryLE  M_CamrySE  M_CamryXLE  \n",
       "7        False      False       False  \n",
       "11        True      False       False  \n",
       "167      False       True       False  \n",
       "225      False      False       False  \n",
       "270      False      False       False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación de librerías\n",
    "#matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Lectura de la información de archivo .csv\n",
    "#data = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTrain_carListings.zip')\n",
    "data = pd.read_csv('../datasets/dataTrain_carListings.zip')\n",
    "\n",
    "# Preprocesamiento de datos para el taller\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data = data.drop(['Model'], axis=1)\n",
    "\n",
    "# Visualización dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y)\n",
    "y = data['Price']\n",
    "X = data.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de datos en set de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Árbol de decisión manual\n",
    "\n",
    "En la celda 1 creen un árbol de decisión **manualmente**  que considere los set de entrenamiento y test definidos anteriormente y presenten el RMSE y MAE del modelo en el set de test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1\n",
    "#Definición de función para calcular el MAE\n",
    "def MAE_calculation(y_test, y_pred):\n",
    "    mae = np.mean(np.abs(y_test - y_pred))\n",
    "    return mae\n",
    "\n",
    "#Definición de función para calcular el RMSE\n",
    "def MSE_calculation(y_true, y_pred):\n",
    "    return np.mean(np.square(y_true - y_pred))\n",
    "    \n",
    "# Definición de la función best_split_reg para calcular cuál es la mejor variable y punto de corte para hacer la bifurcación del árbol en problemas de regresión\n",
    "def best_split_reg(X, y, num_pct):\n",
    "    \n",
    "    # Obtener los percentiles\n",
    "    percentiles = np.percentile(X, np.arange(0, 100, num_pct)).tolist()\n",
    "    \n",
    "    # Agregar los extremos\n",
    "    percentiles = [-np.inf] + percentiles + [np.inf]\n",
    "    \n",
    "    # Inicializar los valores\n",
    "    best_j, best_split, best_gain = None, None, np.inf\n",
    "    \n",
    "    # Recorrer todas las combinaciones de j y split\n",
    "    for j in range(X.shape[1]):\n",
    "        for split in percentiles:\n",
    "            y_l, y_r = y[X.iloc[:, j] < split], y[X.iloc[:, j] >= split]\n",
    "            if y_l.shape[0] > 0 and y_r.shape[0] > 0:\n",
    "                y_mean_l, y_mean_r = y_l.mean(), y_r.mean()\n",
    "                gain = ((y_l - y_mean_l)**2).sum() + ((y_r - y_mean_r)**2).sum()\n",
    "                if gain < best_gain:\n",
    "                    best_j, best_split, best_gain = j, split, gain\n",
    "    \n",
    "    return best_j, best_split, best_gain\n",
    "\n",
    "\n",
    "#Definición de función para calibrar la profundidad del árbol\n",
    "def calibrate_max_depth(num_folds, max_depth_values, X, y):\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    result = []\n",
    "    for max_depth in max_depth_values:\n",
    "        mse_fold = []\n",
    "        for train_index, val_index in kf.split(X):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            tree = tree_grow(X_train, y_train, max_depth=max_depth)\n",
    "            y_pred = tree_predict(X_val, tree)\n",
    "            mse_fold.append(np.mean((y_val - y_pred)**2))\n",
    "        result.append([max_depth, np.mean(mse_fold)])\n",
    "    result = np.array(result)\n",
    "    optimal_max_depth = result[np.argmin(result[:,1]),0]\n",
    "    return result, optimal_max_depth\n",
    "\n",
    "\n",
    "# Definición de la función tree_grow para hacer un crecimiento recursivo del árbol\n",
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # Si solo es una observación\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_std=0, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calcular la mejor división\n",
    "    j, split, gain = best_split_reg(X, y, num_pct)\n",
    "    \n",
    "    # Guardar el árbol y estimar la predicción\n",
    "    y_pred = y.mean() \n",
    "    y_std = y.std()\n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_std=y_std, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    # Revisar el criterio de parada \n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # Continuar creando la partición\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "    # Siguiente iteración para cada partición\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree\n",
    "# Definición de la función tree_predict para hacer predicciones según las variables 'X' y el árbol 'tree'\n",
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "    # Revisar si es el nodo final\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "        if X_l.shape[0] == 0:  # Si el nodo izquierdo está vacio solo continua con el derecho \n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  #  Si el nodo derecho está vacio solo continua con el izquierdo\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "    return predicted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecución del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexing.py:904\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 904\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_key(k, i)\n\u001b[1;32m    905\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexing.py:1518\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan only index by location with a [\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_valid_types\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Can only index by location with a [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_folds \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m      2\u001b[0m max_depth_values \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m11\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m best_max_depth \u001b[39m=\u001b[39m calibrate_max_depth(num_folds, max_depth_values, X_train, y_train)\n\u001b[1;32m      4\u001b[0m tree \u001b[39m=\u001b[39m tree_grow(X_train, y_train, max_depth\u001b[39m=\u001b[39mbest_max_depth)\n\u001b[1;32m      5\u001b[0m y_pred \u001b[39m=\u001b[39m tree_predict(X_test, tree)\n",
      "Cell \u001b[0;32mIn[5], line 45\u001b[0m, in \u001b[0;36mcalibrate_max_depth\u001b[0;34m(num_folds, max_depth_values, X, y)\u001b[0m\n\u001b[1;32m     43\u001b[0m X_train, X_val \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc[train_index], X\u001b[39m.\u001b[39miloc[val_index]\n\u001b[1;32m     44\u001b[0m y_train, y_val \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39miloc[train_index], y\u001b[39m.\u001b[39miloc[val_index]\n\u001b[0;32m---> 45\u001b[0m tree \u001b[39m=\u001b[39m tree_grow(X_train, y_train, max_depth\u001b[39m=\u001b[39;49mmax_depth)\n\u001b[1;32m     46\u001b[0m y_pred \u001b[39m=\u001b[39m tree_predict(X_val, tree)\n\u001b[1;32m     47\u001b[0m mse_fold\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mmean((y_val \u001b[39m-\u001b[39m y_pred)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m))\n",
      "Cell \u001b[0;32mIn[5], line 84\u001b[0m, in \u001b[0;36mtree_grow\u001b[0;34m(X, y, level, min_gain, max_depth, num_pct)\u001b[0m\n\u001b[1;32m     81\u001b[0m tree[\u001b[39m'\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [j, split]\n\u001b[1;32m     82\u001b[0m \u001b[39m# Siguiente iteración para cada partición\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m tree[\u001b[39m'\u001b[39m\u001b[39msl\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tree_grow(X_l, y_l, level \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, min_gain\u001b[39m=\u001b[39;49mmin_gain, max_depth\u001b[39m=\u001b[39;49mmax_depth, num_pct\u001b[39m=\u001b[39;49mnum_pct)\n\u001b[1;32m     85\u001b[0m tree[\u001b[39m'\u001b[39m\u001b[39msr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tree_grow(X_r, y_r, level \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, min_gain\u001b[39m=\u001b[39mmin_gain, max_depth\u001b[39m=\u001b[39mmax_depth, num_pct\u001b[39m=\u001b[39mnum_pct)\n\u001b[1;32m     87\u001b[0m \u001b[39mreturn\u001b[39;00m tree\n",
      "Cell \u001b[0;32mIn[5], line 84\u001b[0m, in \u001b[0;36mtree_grow\u001b[0;34m(X, y, level, min_gain, max_depth, num_pct)\u001b[0m\n\u001b[1;32m     81\u001b[0m tree[\u001b[39m'\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [j, split]\n\u001b[1;32m     82\u001b[0m \u001b[39m# Siguiente iteración para cada partición\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m tree[\u001b[39m'\u001b[39m\u001b[39msl\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tree_grow(X_l, y_l, level \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, min_gain\u001b[39m=\u001b[39;49mmin_gain, max_depth\u001b[39m=\u001b[39;49mmax_depth, num_pct\u001b[39m=\u001b[39;49mnum_pct)\n\u001b[1;32m     85\u001b[0m tree[\u001b[39m'\u001b[39m\u001b[39msr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tree_grow(X_r, y_r, level \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, min_gain\u001b[39m=\u001b[39mmin_gain, max_depth\u001b[39m=\u001b[39mmax_depth, num_pct\u001b[39m=\u001b[39mnum_pct)\n\u001b[1;32m     87\u001b[0m \u001b[39mreturn\u001b[39;00m tree\n",
      "    \u001b[0;31m[... skipping similar frames: tree_grow at line 84 (1 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn[5], line 84\u001b[0m, in \u001b[0;36mtree_grow\u001b[0;34m(X, y, level, min_gain, max_depth, num_pct)\u001b[0m\n\u001b[1;32m     81\u001b[0m tree[\u001b[39m'\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [j, split]\n\u001b[1;32m     82\u001b[0m \u001b[39m# Siguiente iteración para cada partición\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m tree[\u001b[39m'\u001b[39m\u001b[39msl\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tree_grow(X_l, y_l, level \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, min_gain\u001b[39m=\u001b[39;49mmin_gain, max_depth\u001b[39m=\u001b[39;49mmax_depth, num_pct\u001b[39m=\u001b[39;49mnum_pct)\n\u001b[1;32m     85\u001b[0m tree[\u001b[39m'\u001b[39m\u001b[39msr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tree_grow(X_r, y_r, level \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, min_gain\u001b[39m=\u001b[39mmin_gain, max_depth\u001b[39m=\u001b[39mmax_depth, num_pct\u001b[39m=\u001b[39mnum_pct)\n\u001b[1;32m     87\u001b[0m \u001b[39mreturn\u001b[39;00m tree\n",
      "Cell \u001b[0;32mIn[5], line 78\u001b[0m, in \u001b[0;36mtree_grow\u001b[0;34m(X, y, level, min_gain, max_depth, num_pct)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[39mreturn\u001b[39;00m tree   \n\u001b[1;32m     77\u001b[0m \u001b[39m# Continuar creando la partición\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m filter_l \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49miloc[:, j] \u001b[39m<\u001b[39m split\n\u001b[1;32m     79\u001b[0m X_l, y_l \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mloc[filter_l], y\u001b[39m.\u001b[39mloc[filter_l]\n\u001b[1;32m     80\u001b[0m X_r, y_r \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mloc[\u001b[39m~\u001b[39mfilter_l], y\u001b[39m.\u001b[39mloc[\u001b[39m~\u001b[39mfilter_l]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1096\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m   1098\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexing.py:1594\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_getitem_tuple\u001b[39m(\u001b[39mself\u001b[39m, tup: \u001b[39mtuple\u001b[39m):\n\u001b[0;32m-> 1594\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_tuple_indexer(tup)\n\u001b[1;32m   1595\u001b[0m     \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1596\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexing.py:906\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(k, i)\n\u001b[1;32m    905\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 906\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    907\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mLocation based indexing can only have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    908\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_valid_types\u001b[39m}\u001b[39;00m\u001b[39m] types\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[39mreturn\u001b[39;00m key\n",
      "\u001b[0;31mValueError\u001b[0m: Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "max_depth_values = range(1,11)\n",
    "best_max_depth = calibrate_max_depth(num_folds, max_depth_values, X_train, y_train)\n",
    "tree = tree_grow(X_train, y_train, max_depth=best_max_depth)\n",
    "y_pred = tree_predict(X_test, tree)\n",
    "RMSE = MSE_calculation(y_test, y_pred)**0.5\n",
    "MAE = MAE_calculation(y_test, y_pred)\n",
    "print('RMSE: ', RMSE)\n",
    "print('MAE: ', MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Bagging manual\n",
    "\n",
    "En la celda 2 creen un modelo bagging **manualmente** con 10 árboles de regresión y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2\n",
    "# Celda 2\n",
    "# Creación de 10 muestras de bootstrap \n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_B = 10\n",
    "\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "samples\n",
    "\n",
    "# DataFrame para guardar las predicciones de cada árbol\n",
    "y_pred = pd.DataFrame(index=y_test.index, columns=[list(range(n_B))])\n",
    "\n",
    "# Entrenamiento de un árbol sobre cada muestra boostrap y predicción sobre los datos de test\n",
    "for i, sample in enumerate(samples):\n",
    "    X_trainb = X_train.iloc[sample, :]\n",
    "    y_trainb = y_train.iloc[sample]\n",
    "    tree = tree_grow(X_trainb, y_trainb, level=0, min_gain=0.001, max_depth=8, num_pct=10)\n",
    "    y_pred.iloc[:,i] = tree_predict(X_test, tree)\n",
    "  \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Bagging con librería\n",
    "\n",
    "En la celda 3, con la librería sklearn, entrenen un modelo bagging con 10 árboles de regresión y el parámetro `max_features` igual a `log(n_features)` y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3\n",
    "\n",
    "base_clf = DecisionTreeClassifier()\n",
    "max_features = int(np.log2(X_train.shape[1]))\n",
    "bag_clf = BaggingClassifier(base_estimator=base_clf, max_features=max_features, random_state=45)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "num_correct = np.sum(y_pred == y_test)\n",
    "total = len(y_test)\n",
    "accuracy = num_correct / total\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Random forest con librería\n",
    "\n",
    "En la celda 4, usando la librería sklearn entrenen un modelo de Randon Forest para regresión  y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4\n",
    "\n",
    "# Definición de modelo Random Forest para un problema de clasificación\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "num_correct = np.sum(y_pred == y_test)\n",
    "total = len(y_test)\n",
    "accuracy = num_correct / total\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Calibración de parámetros Random forest\n",
    "\n",
    "En la celda 5, calibren los parámetros max_depth, max_features y n_estimators del modelo de Randon Forest para regresión, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - XGBoost con librería\n",
    "\n",
    "En la celda 6 implementen un modelo XGBoost de regresión con la librería sklearn y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Calibración de parámetros XGBoost\n",
    "\n",
    "En la celda 7 calibren los parámetros learning rate, gamma y colsample_bytree del modelo XGBoost para regresión, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Comparación y análisis de resultados\n",
    "En la celda 8 comparen los resultados obtenidos de los diferentes modelos (random forest y XGBoost) y comenten las ventajas del mejor modelo y las desventajas del modelo con el menor desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
